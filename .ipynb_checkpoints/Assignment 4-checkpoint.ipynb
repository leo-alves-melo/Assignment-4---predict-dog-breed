{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Engineer your features. Here you do not have them for free. You need to think of possible ways for transforming the collected data into meaningful features. For some ideas, consider traditional features such as texture features, color features, bags of visual words or more powerful ones involving CNNs. If you cannot think of anything, talk to the professor for some ideas.\n",
    "\n",
    "2. Propose classification techniques to solve the problem. Suggestions here are the CNN directly, or SVMs/Random Forests allied with CNNs through the use of transfer learning.\n",
    "\n",
    "3. Consider using data augmentation in the training (what about in the testing as well?)\n",
    "\n",
    "4. Observation: You are free to use any solution to help you extract the features at this point.\n",
    "\n",
    "5. Report all of your results for the validation and test data. The labels for the test will be released one week before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definicoes\n",
    "dataFolder = 'data/'\n",
    "trainFolder = dataFolder + 'train/'\n",
    "validationFolder = dataFolder + 'val/'\n",
    "testFolder = dataFolder + 'test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        # first set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode=\"same\",\n",
    "        input_shape=(depth, height, width)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "        # second set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    " \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        # if a weights path is supplied (inicating that the model was pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Funcoes\n",
    "\n",
    "#Retorna o vetor da imagem dado o nome do seu arquivo\n",
    "def le_imagem(name):\n",
    "    return io.imread(name,plugin='matplotlib') \n",
    "\n",
    "#Retorna o vetor da imagem e a classe dado o caminho do arquivo\n",
    "def le_imagem_e_classe(name):\n",
    "    img = le_imagem(name)\n",
    "    classe = int(name.split('/')[2].split('_')[0])\n",
    "    return img, classe\n",
    "\n",
    "#Retorna o caminho de todas as imagens dado a pasta\n",
    "def nome_das_imagens(pasta):\n",
    "    return glob(pasta + '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Le uma imagem\n",
    "img, classe1 = le_imagem_e_classe(trainFolder + '00_0004.jpg')\n",
    "largura = img.shape[1]\n",
    "altura = img.shape[0]\n",
    "profundidade = img.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[188 172 121 ... 145 202 191]\n",
      "  [145 202 191 ... 208 169 218]\n",
      "  [209 170 219 ... 233 225 202]\n",
      "  ...\n",
      "  [ 88 102 102 ... 230 218 180]\n",
      "  [192 177 120 ... 143 208 195]\n",
      "  [143 208 195 ...  63  74 112]]\n",
      "\n",
      " [[109 120  85 ... 230 218 180]\n",
      "  [192 177 120 ... 143 208 195]\n",
      "  [143 208 195 ...  88  97  77]\n",
      "  ...\n",
      "  [  4   4   4 ...  20  24  23]\n",
      "  [ 18  24  26 ... 215 200 145]\n",
      "  [197 179 113 ...   1   5   4]]\n",
      "\n",
      " [[  2   7   6 ...  21  22  23]\n",
      "  [ 16  23  25 ... 215 200 143]\n",
      "  [197 179 113 ...   1   6   5]\n",
      "  ...\n",
      "  [218 212 180 ... 218 238 239]\n",
      "  [223 240 241 ... 217 195 233]\n",
      "  [227 205 233 ... 199 187 161]]]\n",
      "vai\n",
      "[[[188 172 121 ... 145 202 191]\n",
      "  [145 202 191 ... 208 169 218]\n",
      "  [209 170 219 ... 233 225 202]\n",
      "  ...\n",
      "  [ 88 102 102 ... 230 218 180]\n",
      "  [192 177 120 ... 143 208 195]\n",
      "  [143 208 195 ...  63  74 112]]\n",
      "\n",
      " [[109 120  85 ... 230 218 180]\n",
      "  [192 177 120 ... 143 208 195]\n",
      "  [143 208 195 ...  88  97  77]\n",
      "  ...\n",
      "  [  4   4   4 ...  20  24  23]\n",
      "  [ 18  24  26 ... 215 200 145]\n",
      "  [197 179 113 ...   1   5   4]]\n",
      "\n",
      " [[  2   7   6 ...  21  22  23]\n",
      "  [ 16  23  25 ... 215 200 143]\n",
      "  [197 179 113 ...   1   6   5]\n",
      "  ...\n",
      "  [218 212 180 ... 218 238 239]\n",
      "  [223 240 241 ... 217 195 233]\n",
      "  [227 205 233 ... 199 187 161]]]\n",
      "foi?\n",
      "(3, 200, 200)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (5, 5), input_shape=(3, 200, 2..., padding=\"same\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, (5, 5), padding=\"same\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected activation_82 to have shape (2,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-158-39eb13d3987b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'foi?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1631\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1480\u001b[0;31m                                     exception_prefix='target')\n\u001b[0m\u001b[1;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[1;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected activation_82 to have shape (2,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "#Treina essa unica imagem\n",
    "model = LeNet.build(width=largura, height=altura, depth=profundidade, classes=2)\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print(img.shape)\n",
    "print(img)\n",
    "img = np.reshape(img,(3,200,200))\n",
    "print('vai')\n",
    "print(img)\n",
    "print('foi?')\n",
    "print(img.shape)\n",
    "model.fit(np.array([img]),np.array([0]))\n",
    "print(model.predict([img]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
