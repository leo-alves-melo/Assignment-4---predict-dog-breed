{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Engineer your features. Here you do not have them for free. You need to think of possible ways for transforming the collected data into meaningful features. For some ideas, consider traditional features such as texture features, color features, bags of visual words or more powerful ones involving CNNs. If you cannot think of anything, talk to the professor for some ideas.\n",
    "\n",
    "2. Propose classification techniques to solve the problem. Suggestions here are the CNN directly, or SVMs/Random Forests allied with CNNs through the use of transfer learning.\n",
    "\n",
    "3. Consider using data augmentation in the training (what about in the testing as well?)\n",
    "\n",
    "4. Observation: You are free to use any solution to help you extract the features at this point.\n",
    "\n",
    "5. Report all of your results for the validation and test data. The labels for the test will be released one week before the deadline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from skimage.transform import resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Definicoes\n",
    "dataFolder = 'data/'\n",
    "trainFolder = dataFolder + 'train/'\n",
    "validationFolder = dataFolder + 'val/'\n",
    "testFolder = dataFolder + 'test/'\n",
    "\n",
    "numberOfClasses = 83\n",
    "largura = 200\n",
    "altura = 200\n",
    "profundidade = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes\n",
    "\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, weightsPath=None):\n",
    "        # initialize the model\n",
    "        model = Sequential()\n",
    "        # first set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(20, 5, 5, border_mode=\"same\", input_shape=(height, width, depth)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "        # second set of CONV => RELU => POOL\n",
    "        model.add(Convolution2D(50, 5, 5, border_mode=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), dim_ordering=\"th\"))\n",
    "        # set of FC => RELU layers\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    " \n",
    "        # softmax classifier\n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "        # if a weights path is supplied (inicating that the model was pre-trained), then load the weights\n",
    "        if weightsPath is not None:\n",
    "            model.load_weights(weightsPath)\n",
    " \n",
    "        # return the constructed network architecture\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "banana\n"
     ]
    }
   ],
   "source": [
    "#Funcoes\n",
    "\n",
    "#Retorna o vetor da imagem dado o nome do seu arquivo\n",
    "def le_imagem(name):\n",
    "    return io.imread(name,plugin='matplotlib') \n",
    "\n",
    "#Retorna o vetor da imagem e a classe dado o caminho do arquivo\n",
    "def le_imagem_e_classe(name):\n",
    "    img = le_imagem(name)\n",
    "    img = resize(img, (200, 200))\n",
    "    classe = np_utils.to_categorical(int(name.split('/')[2].split('_')[0]), numberOfClasses)\n",
    "    return img, classe\n",
    "\n",
    "#Retorna o caminho de todas as imagens dado a pasta\n",
    "def nome_das_imagens(pasta):\n",
    "    return glob(pasta + '*')\n",
    "\n",
    "#Retorna o numero correspondente a predicao\n",
    "def categorical_to_number(vector):\n",
    "    maior = 0\n",
    "    for i in range(len(vector)):\n",
    "        if vector[i] > vector[maior]:\n",
    "            maior = i\n",
    "    return maior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lendo imagens de treino\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lido\n"
     ]
    }
   ],
   "source": [
    "#Le as imagens de treino\n",
    "print('lendo imagens de treino')\n",
    "X_train = []\n",
    "y_train = []\n",
    "for file in nome_das_imagens(trainFolder[0:1000]):\n",
    "    img, classe = le_imagem_e_classe(file)\n",
    "    X_train.append(img)\n",
    "    y_train.append(classe)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "print('lido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lendo imagens de validacao\n",
      "lido\n"
     ]
    }
   ],
   "source": [
    "#Le as imagens de validacao\n",
    "print('lendo imagens de validacao')\n",
    "X_val = []\n",
    "y_val = []\n",
    "for file in nome_das_imagens(validationFolder):\n",
    "    #img, classe = le_imagem_e_classe(file)\n",
    "    #X_val.append(img)\n",
    "    #y_val.append(classe)\n",
    "    pass\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "print('lido')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelando LeNet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(20, (5, 5), input_shape=(200, 200,..., padding=\"same\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(50, (5, 5), padding=\"same\")`\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:15: UserWarning: Update your `MaxPooling2D` call to the Keras 2 API: `MaxPooling2D(pool_size=(2, 2), strides=(2, 2), data_format=\"channels_first\")`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "treinando\n",
      "Epoch 1/1\n",
      "8300/8300 [==============================] - 1831s 221ms/step - loss: 4.4092 - acc: 0.0175\n",
      "treinado\n"
     ]
    }
   ],
   "source": [
    "#Treina essa unica imagem\n",
    "print('modelando LeNet')\n",
    "model = LeNet.build(width=largura, height=altura, depth=profundidade, classes=numberOfClasses)\n",
    "opt = SGD(lr=0.01)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "print('treinando')\n",
    "model.fit(X_train,y_train)\n",
    "print('treinado')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predizendo X_train\n"
     ]
    }
   ],
   "source": [
    "#Testa o modelo treinado\n",
    "print('predizendo X_train')\n",
    "predicted = model.predict(X_train[0:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testando os acertos\n",
      "acertos: 1.8%\n"
     ]
    }
   ],
   "source": [
    "print('Testando os acertos')\n",
    "acertos = 0.0\n",
    "for i in range(len(predicted)):\n",
    "    if categorical_to_number(predicted[i]) == categorical_to_number(y_train[i]):\n",
    "        acertos += 1.0\n",
    "print('acertos: ' + str(100.0 * acertos/float(len(predicted))) + '%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
